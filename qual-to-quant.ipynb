{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Environment Setup\n","\n","Actions performed:\n","1. Sets up & tests connectivity to Azure OpenAI\n","2. Defines functions to call AzureOpenAI"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import openai\n","from urllib.parse import urlparse\n","import dotenv\n","\n","\n","# Load environment variables from .env file\n","dotenv_path = \".\"\n","dotenv.load_dotenv(dotenv_path)\n","print(\"Azure OpenAI Deployment: \", os.getenv('DEPLOYMENT_NAME'))\n","\n","import os\n","openai.api_type = \"azure\"\n","openai.api_version = os.getenv(\"API_VERSION\")\n","openai.api_base = os.getenv(\"ENDPOINT\")  # Your Azure OpenAI resource's endpoint value.\n","openai.api_key = os.getenv(\"API_KEY\")\n","\n","# function below calls Azure OpenAI and returns a text response\n","def run_chat_completion(prompt_template):\n","    resp = openai.ChatCompletion.create(\n","        engine=os.getenv('DEPLOYMENT_NAME'),\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You're a helpful analyst.\"},\n","            {\"role\": \"user\", \"content\": prompt_template}\n","        ]\n","    )\n","\n","    return resp\n","\n","# function below calls Azure OpenAI and returns a JSON response - note you also need to ask for JSON formatting in your prompt\n","def run_chat_completion_json(prompt_template):\n","    resp = openai.ChatCompletion.create(\n","        engine=os.getenv('DEPLOYMENT_NAME'),\n","        response_format={ \"type\": \"json_object\" },\n","        messages=[\n","            {\"role\": \"system\", \"content\": \"You're a helpful analyst.\"},\n","            {\"role\": \"user\", \"content\": prompt_template}\n","        ]\n","    )\n","\n","    return resp\n","\n","\n","# Example usage:\n","new_prompt_template = \"What is Australia like for food in 10 words or less?\"\n","response = run_chat_completion(new_prompt_template)\n","\n","\n","print(response[\"choices\"][0][\"message\"][\"content\"])"]},{"cell_type":"markdown","metadata":{},"source":["### Step 2: Import Data\n","\n","Source: https://www.kaggle.com/datasets/parve05/customer-review-dataset/\n","1. Sign up for a free Kaggle account if you haven't already\n","2. Download the dataset (it's in a zip file)\n","3. Extract the file from the zip and save it in this folder. The datafile was called \"redmi6.csv\" when I last accessed, just note the name and if it is different update the code below so it can be found by the script"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import csv\n","\n","file_path = 'redmi6.csv'\n","data = []\n","feedback = []\n","\n","with open(file_path, 'r', encoding='utf-8', errors='replace') as csvfile:\n","    csvreader = csv.reader(csvfile)\n","\n","    for row in csvreader:\n","        # print(row)\n","        data.append(row)\n","        feedback.append(row[5])\n","\n","\n","print(\"CSV file loaded\")"]},{"cell_type":"markdown","metadata":{},"source":["### Step 3: Import Feedback data\n","\n","Actions:\n","1. Loads the Kaggle data into memory\n","2. Prints out the first two rows to demonstrate what is in the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Total rows of data:\", len(feedback))\n","print(\"First 2 feedback items:\")\n","print(feedback[:2])"]},{"cell_type":"markdown","metadata":{},"source":["### Step 4. Understand sentiment based on feedback\n","\n","Now let's ask GPT4 to read summarise what the reviewers thought about the mobile phone."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_prompt_template = f\"Using the feedback below what is the general sentiment? {feedback}\"\n","response = run_chat_completion(new_prompt_template)\n","\n","\n","print(response[\"choices\"][0][\"message\"][\"content\"])"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 5. Categorise the feedback\n","\n","A paragraph or two is good, but as humans often we like to group information to better understand it. Let's ask GPT4 to instead summarise the information and group it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_prompt_template = f\"Using the feedback below what are the main categories it falls into? Provide these as a list, grouped in positive/neutral/negative sentiment. Feedback: {feedback}\"\n","response = run_chat_completion(new_prompt_template)\n","\n","\n","print(response[\"choices\"][0][\"message\"][\"content\"])"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 6. Make the feedback understandable by an app\n","\n","One of the amazing things GPT4 can do is turn QUALitative data (such as the results above) into QUANTitative data. This is incredibly powerful, as it enables us to build the output of a document analysis into a workflow.\n","\n","For example, you could review a supplier contract to confirm if there is a limitation of liability clause in there. If there isn't one, GPT4 could return \"false\", and you could then build a workflow that requests the supplier to amend the contract and ensure they include the appropriate clause.\n","\n","OpenAI have built a specific capability we can leverage is the \"response_format={ \"type\": \"json_object\" } argument. This instructs the LLM to return a JSON-compliant response which apps can then use."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_prompt_template = f\"Using the feedback below what are the main themes shared? Respond with a JSON array, with each theme a key value pair, capturing the general sentiment of that theme as the value (positive/neutral/negative). {feedback}.\"\n","response = run_chat_completion_json(new_prompt_template)\n","\n","\n","print(response[\"choices\"][0][\"message\"][\"content\"])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.0.0"}},"nbformat":4,"nbformat_minor":2}
